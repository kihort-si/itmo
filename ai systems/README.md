# Системы исскуственного интеллекта
## **О предмете**
В курсе рассматриваются методы резолюции целей при решении интеллектуальных задач, методы построения баз знаний в интеллектуальных системах и методы редуцирования пространства поиска.

Продолжительность: 1 семестр.

## **Лабораторные работы**

### [**Лабораторная работа №1**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab1)

**Часть 1. Создание базы знаний и выполнение запросов в Prolog**

Создание базы знаний в среде Prolog

Предметная область – Ваше семейное дерево

1. Создать не менее 30 объектов – членов вашей семьи.
2. Факты, отражающие состояние – события, регистрируемые органами ЗАГС (рождение, смерть, заключение брака, расторжение брака).
3. Создать не менее 30 правил, определяющих на основании событий состояния членов семьи и отношения между ними.
4. Правила должны учитывать темпоральность состояний с точностью до года.

**Часть 2. Создание онтологии в Protege**

Преобразовать факты и отношения из Prolog в концепты и свойства в онтологии. Описать классы и свойства в онтологии, которые соответствуют объектам и отношениям из базы знаний. Например, если у были классы "Человек" и "Машина" и свойство "возраст", создайте аналогичные классы и свойства в онтологии в Protege.

### [**Лабораторная работа №2**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab2)
![Python](https://github.com/kihort-si/itmo/blob/main/common/python.svg)

Создать программу, которая позволяет пользователю ввести запрос через командную строку. Например, информацию о себе, своих интересах и предпочтениях в контексте выбора видеоигры - на основе фактов из БЗ (из первой лабы)/Онтологии(из второй).

Использовать введенные пользователем данные, чтобы выполнить логические запросы к БЗ/Онтологии.

На основе полученных результатов выполнения запросов, система должна предоставить рекомендации или советы, связанные с выбором из БЗ или онтологии.

Система должна выдавать рекомендации после небольшого диалога с пользователем.

### [**Лабораторная работа №3**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab3)
![Jupiter Notebook](https://github.com/kihort-si/itmo/blob/main/common/jupiter.svg)

Датасет: [Обучение студентов](https://github.com/kihort-si/itmo/blob/main/ai%20systems/lab3/data/Student_Performance.csv)

Получите и визуализируйте (графически) статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили).

Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и нормировка.

Разделите данные на обучающий и тестовый наборы данных.

Реализуйте линейную регрессию с использованием метода наименьших квадратов без использования сторонних библиотек, кроме NumPy и Pandas (для использования коэффициентов использовать библиотеки тоже нельзя). Использовать минимизацию суммы квадратов разностей между фактическими и предсказанными значениями для нахождения оптимальных коэффициентов.

Постройте **три модели** с различными наборами признаков.

Для каждой модели проведите оценку производительности, используя метрику коэффициент детерминации, чтобы измерить, насколько хорошо модель соответствует данным.

Сравните результаты трех моделей и сделайте выводы о том, какие признаки работают лучше всего для каждой модели.

### [**Лабораторная работа №4**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab4)
![Jupiter Notebook](https://github.com/kihort-si/itmo/blob/main/common/jupiter.svg)

Датасет: [Диабет](https://github.com/kihort-si/itmo/blob/main/ai%20systems/lab4/data/diabetes.csv)

Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и масштабирование.

Получите и визуализируйте (графически) статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили), постройте 3d-визуализацию признаков.

Реализуйте метод k-ближайших соседей ****без использования сторонних библиотек, кроме NumPy и Pandas.

Постройте две модели k-NN с различными наборами признаков:
- Модель 1: Признаки случайно отбираются.
- Модель 2: Фиксированный набор признаков, который выбирается заранее.

Для каждой модели проведите оценку на тестовом наборе данных при разных значениях k. Выберите несколько различных значений k, например, k=3, k=5, k=10, и т. д. Постройте матрицу ошибок.

### [**Лабораторная работа №5**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab5)
![Jupiter Notebook](https://github.com/kihort-si/itmo/blob/main/common/jupiter.svg)

Датасет: [Оценки студентов](https://github.com/kihort-si/itmo/blob/main/ai%20systems/lab5/data/DATA%20(1).csv)

Ввести метрику: студент успешный/неуспешный на основании грейда

Отобрать случайным образом sqrt(n) признаков

Реализовать без использования сторонних библиотек построение дерева решений (дерево не бинарное, numpy и pandas использовать можно, использовать список списков для реализации дерева - нельзя) для решения задачи бинарной классификации

Провести оценку реализованного алгоритма с использованием Accuracy, precision и recall

Построить кривые AUC-ROC и AUC-PR (в пунктах 4 и 5 использовать библиотеки нельзя)

### [**Лабораторная работа №6**](https://github.com/kihort-si/itmo/tree/main/ai%20systems/lab6)
![Jupiter Notebook](https://github.com/kihort-si/itmo/blob/main/common/jupiter.svg)

Датасет: [Диабет](https://github.com/kihort-si/itmo/blob/main/ai%20systems/lab6/data/diabetes.csv)

Загрузите выбранный датасет и выполните предварительную обработку данных.

Получите и визуализируйте (графически) статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили).

Разделите данные на обучающий и тестовый наборы в соотношении, которое вы считаете подходящим.

Реализуйте логистическую регрессию "с нуля" без использования сторонних библиотек, кроме NumPy и Pandas. Ваша реализация логистической регрессии должна включать в себя:
- Функцию для вычисления гипотезы (sigmoid function).
- Функцию для вычисления функции потерь (log loss).
- Метод обучения, который включает в себя градиентный спуск.
- Возможность варьировать гиперпараметры, такие как коэффициент обучения (learning rate) и количество итераций.

Исследование гиперпараметров:

Проведите исследование влияния гиперпараметров на производительность модели. Варьируйте следующие гиперпараметры:
- Коэффициент обучения (learning rate).
- Количество итераций обучения.
- Метод оптимизации (например, градиентный спуск или оптимизация Ньютона).

Оценка модели:

Для каждой комбинации гиперпараметров оцените производительность модели на тестовом наборе данных, используя метрики, такие как accuracy, precision, recall и F1-Score.

Сделайте выводы о том, какие значения гиперпараметров наилучшим образом работают для данного набора данных и задачи классификации. Обратите внимание на изменение производительности модели при варьировании гиперпараметров.
