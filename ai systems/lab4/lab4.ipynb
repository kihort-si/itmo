{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Лабораторная работа №4",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "data\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Проведите предварительную обработку данных, включая обработку отсутствующих значений, кодирование категориальных признаков и масштабирование.\n",
   "id": "689f5a7884d5b2d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверим наличие пропущенных значений в датасете:",
   "id": "ac12db31b5af1fc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Пропуски до обработки:\\n\", data.isnull().sum(), \"\\n\")",
   "id": "f2036b254d2671b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Пропущенных значений нет.",
   "id": "fffcae866d96db78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Заменить нулевые значения в некоторых столбцах на NaN, так как нули в этих признаках означают отсутствие измерения.",
   "id": "424c4d21c3cfdee5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols_with_zeros = [\n",
    "    'Glucose',\n",
    "    'BloodPressure',\n",
    "    'SkinThickness',\n",
    "    'Insulin',\n",
    "    'BMI'\n",
    "]\n",
    "\n",
    "data[cols_with_zeros] = data[cols_with_zeros].replace(0, np.nan)\n",
    "\n",
    "print(\"Пропуски после замены нулей на NaN:\\n\", data.isnull().sum(), \"\\n\")"
   ],
   "id": "6425b512983f62e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В нашем датасете все признаки числовые, кроме целевого Outcome, кодировать ничего не нужно.",
   "id": "d1833542ae7d7bc4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Получите и визуализируйте (графически) статистику по датасету (включая количество, среднее значение, стандартное отклонение, минимум, максимум и различные квантили), постройте 3d-визуализацию признаков.",
   "id": "3a33458ca256a9b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Получим статистику по датасету:",
   "id": "afed943e08eeba87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats = data.describe()\n",
    "print(stats)"
   ],
   "id": "627e8c3d560a606d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Построим гистограммы и boxplot для всех признаков:",
   "id": "5899ec87972417ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.hist(bins=20, figsize=(12,10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "data.plot(kind='box')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = data['Glucose']\n",
    "y = data['BMI']\n",
    "z = data['Age']\n",
    "\n",
    "ax.scatter(x, y, z, c=data['Outcome'], cmap='viridis', alpha=0.7)\n",
    "ax.set_xlabel('Glucose')\n",
    "ax.set_ylabel('BMI')\n",
    "ax.set_zlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = data['Pregnancies']\n",
    "y = data['BMI']\n",
    "z = data['Age']\n",
    "\n",
    "ax.scatter(x, y, z, c=data['Outcome'], cmap='viridis', alpha=0.7)\n",
    "ax.set_xlabel('Pregnancies')\n",
    "ax.set_ylabel('BMI')\n",
    "ax.set_zlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = data['Pregnancies']\n",
    "y = data['Glucose']\n",
    "z = data['Age']\n",
    "\n",
    "ax.scatter(x, y, z, c=data['Outcome'], cmap='viridis', alpha=0.7)\n",
    "ax.set_xlabel('Pregnancies')\n",
    "ax.set_ylabel('Glucose')\n",
    "ax.set_zlabel('Age')\n",
    "plt.show()"
   ],
   "id": "77e8f592aa2747c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Построим матрицу крорреляций признаков:",
   "id": "3fd5c414ae0c1632"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "corr_matrix = data.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar(label='Коэффициент корреляции')\n",
    "plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
    "plt.title(\"Матрица корреляции признаков\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "72c05eb7d0471f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Выполним min-max масштабирование для всех признаков, кроме целевого Outcome:\n",
    "\n",
    "$$ X_{\\text{norm}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}} $$"
   ],
   "id": "3dae090fe7e5369d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "X_norm = X.copy()\n",
    "for col in X.columns:\n",
    "    min_val = X[col].min()\n",
    "    max_val = X[col].max()\n",
    "    X_norm[col] = (X[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "data_norm = pd.concat([X_norm, y], axis=1)\n",
    "\n",
    "print(data_norm.head())"
   ],
   "id": "a7fabcccf22a74fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Все значения в диапазоне [0, 1].\n",
    "\n",
    "Получим статистику по нормализованному датасету:"
   ],
   "id": "275699d6c6099a99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stats = data_norm.describe()\n",
    "print(stats)"
   ],
   "id": "2969eef920f57363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Построим гистограммы и boxplot для всех признаков нормализованного датасета:",
   "id": "4ade1826b2438de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_norm.hist(bins=20, figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "data_norm.plot(kind='box')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f462b439a9d9e94c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Реализуйте метод k-ближайших соседей ****без использования сторонних библиотек, кроме NumPy и Pandas.\n",
   "id": "643393ab9965c7b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Перед обучением разделим данные на обучающую и тестовую выборки (80/20), выполним нормализацию на обучающей выборке и применим те же параметры нормализации к тестовой выборке.\n",
    "\n",
    "Датасет разделяется на обучающую выборку $X_{\\text{train}}, y_{\\text{train}}$\n",
    "и тестовую выборку $X_{\\text{test}}, y_{\\text{test}}$.\n",
    "Разделение выполняется случайным образом с фиксированным генератором случайных чисел\n",
    "для воспроизводимости результатов."
   ],
   "id": "b7ab17e66f590fcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_df = data.drop('Outcome', axis=1).copy()\n",
    "y_sr = data['Outcome'].astype(int).copy()\n",
    "\n",
    "def train_test_split_df(X: pd.DataFrame, y: pd.Series, seed=42, test_size=0.2):\n",
    "    n = len(X)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    cut = int(n * (1 - test_size))\n",
    "    train_idx, test_idx = idx[:cut], idx[cut:]\n",
    "    return (X.iloc[train_idx].reset_index(drop=True),\n",
    "            X.iloc[test_idx].reset_index(drop=True),\n",
    "            y.iloc[train_idx].reset_index(drop=True),\n",
    "            y.iloc[test_idx].reset_index(drop=True))\n",
    "\n",
    "def fit_minmax(X: pd.DataFrame):\n",
    "    mins = X.min(axis=0)\n",
    "    maxs = X.max(axis=0)\n",
    "    denom = (maxs - mins).replace(0, 1.0)\n",
    "    return mins, denom\n",
    "\n",
    "def transform_minmax(X: pd.DataFrame, mins: pd.Series, denom: pd.Series):\n",
    "    return (X - mins) / denom\n",
    "\n",
    "X_train_df, X_test_df, y_train_sr, y_test_sr = train_test_split_df(X_df, y_sr, seed=42, test_size=0.2)\n",
    "mins, denom = fit_minmax(X_train_df)\n",
    "X_train_norm = transform_minmax(X_train_df, mins, denom)\n",
    "X_test_norm  = transform_minmax(X_test_df,  mins, denom)\n",
    "\n",
    "print(\"HEAD (train, norm):\")\n",
    "display(X_train_norm.head())\n",
    "print(\"DESCRIBE (train, norm):\")\n",
    "display(X_train_norm.describe().T)"
   ],
   "id": "4ed671f29c9e51bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Для классификации нового объекта алгоритм ищет $k$ наиболее близких обучающих\n",
    "примеров и относит данный объект к тому классу, который наиболее часто встречается среди этих соседей.\n",
    "\n",
    "Пусть обучающая выборка состоит из $N$ объектов:\n",
    "$$\n",
    "\\mathcal{D} = \\{(x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\},\n",
    "$$\n",
    "где $x_i \\in \\mathbb{R}^m$ — вектор признаков, а $y_i \\in \\{0,1\\}$ — метка класса.\n",
    "Для нового объекта $x^*$ вычисляется расстояние до всех точек обучающей выборки.\n",
    "В данной работе используется евклидово расстояние:\n",
    "\n",
    "$$\n",
    "d(x^*, x_i) = \\sqrt{\\sum_{j=1}^{m} (x_j^* - x_{ij})^2}.\n",
    "$$\n",
    "\n",
    "Затем выбираются индексы $k$ ближайших соседей:\n",
    "$$\n",
    "N_k(x^*) = \\operatorname{arg\\,min}_{i_1,\\dots,i_k} d(x^*, x_{i_j}).\n",
    "$$\n",
    "\n",
    "Класс нового объекта определяется по большинству меток среди найденных соседей:\n",
    "$$\n",
    "\\hat{y}(x^*) =\n",
    "\\begin{cases}\n",
    "1, & \\text{если } \\frac{1}{k} \\sum\\limits_{i \\in N_k(x^*)} y_i \\ge 0.5,\\\\\n",
    "0, & \\text{иначе.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Для оценки эффективности классификации используется метрика точность:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{n_{\\text{test}}}\n",
    "\\sum_{i=1}^{n_{\\text{test}}} [y_i = \\hat{y}_i],\n",
    "$$\n",
    "где $[y_i = \\hat{y}_i] = 1$, если предсказание совпадает с истинной меткой, и $0$ иначе.\n",
    "Эта метрика отражает долю правильно классифицированных примеров на тестовой выборке.\n",
    "\n",
    "Для анализа ошибок классификации строится матрица ошибок:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\text{TP} & \\text{FN} \\\\\n",
    "\\text{FP} & \\text{TN}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "где:\n",
    "- TP (True Positive) — число объектов класса 1, правильно классифицированных;\n",
    "- TN (True Negative) — число объектов класса 0, правильно классифицированных;\n",
    "- FP (False Positive) — объекты класса 0, ошибочно отнесённые к 1;\n",
    "- FN (False Negative) — объекты класса 1, ошибочно отнесённые к 0.\n"
   ],
   "id": "3e9834ab61c34ab7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def knn_predict_batch(X_train_np, y_train_np, X_test_np, k=5):\n",
    "    preds = np.empty(X_test_np.shape[0], dtype=int)\n",
    "    for i, x in enumerate(X_test_np):\n",
    "        dists = np.sqrt(np.sum((X_train_np - x) ** 2, axis=1))\n",
    "        nn_idx = np.argpartition(dists, kth=k-1)[:k]\n",
    "        labels = y_train_np[nn_idx]\n",
    "        counts = np.bincount(labels)\n",
    "        if (counts.max() != 0) and (np.sum(counts == counts.max()) == 1):\n",
    "            preds[i] = np.argmax(counts)\n",
    "        else:\n",
    "            preds[i] = int(np.rint(labels.mean()))\n",
    "    return preds\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    y_pred = np.asarray(y_pred, dtype=int)\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "def confusion_matrix_df(y_true, y_pred, labels=(0, 1)):\n",
    "    ct = pd.crosstab(\n",
    "        pd.Series(y_true, name='True').astype(pd.CategoricalDtype(categories=labels)),\n",
    "        pd.Series(y_pred, name='Pred').astype(pd.CategoricalDtype(categories=labels)),\n",
    "        dropna=False\n",
    "    )\n",
    "    return ct.reindex(index=labels, columns=labels, fill_value=0)\n",
    "\n",
    "def run_knn_report(features, k=5, seed=42):\n",
    "    X_train_df, X_test_df, y_train_sr, y_test_sr = train_test_split_df(X_df, y_sr, seed=seed, test_size=0.2)\n",
    "    y_train_sr = y_train_sr.astype(int)\n",
    "    y_test_sr = y_test_sr.astype(int)\n",
    "\n",
    "    mins, denom = fit_minmax(X_train_df)\n",
    "    X_train_norm = transform_minmax(X_train_df, mins, denom)\n",
    "    X_test_norm  = transform_minmax(X_test_df,  mins, denom)\n",
    "\n",
    "    cols = list(X_df.columns) if features == 'ALL' else list(features)\n",
    "\n",
    "    Xtr = X_train_norm[cols].to_numpy(dtype=float)\n",
    "    Xte = X_test_norm[cols].to_numpy(dtype=float)\n",
    "    ytr = y_train_sr.to_numpy(dtype=int)\n",
    "    yte = y_test_sr.to_numpy(dtype=int)\n",
    "\n",
    "    print(f\"Train size: {len(Xtr)}\")\n",
    "    print(y_train_sr.astype(float).value_counts().sort_index())\n",
    "    print()\n",
    "    print(f\"Test size: {len(Xte)}\")\n",
    "    print(y_test_sr.astype(float).value_counts().sort_index())\n",
    "\n",
    "    y_pred = knn_predict_batch(Xtr, ytr, Xte, k=k)\n",
    "    print(\"\\nОценка модели: \", accuracy_score(yte, y_pred))\n",
    "\n",
    "    display(X_train_norm[cols].head())\n",
    "\n",
    "    return y_pred, yte\n",
    "\n",
    "def plot_confusion_matrix(cm_df, title=\"Confusion matrix\"):\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm_df.values, cmap='Greens')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Pred'); ax.set_ylabel('True')\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels(cm_df.columns); ax.set_yticklabels(cm_df.index)\n",
    "    for (i, j), v in np.ndenumerate(cm_df.values):\n",
    "        ax.text(j, i, int(v), ha='center', va='center')\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "3c053184e0948bcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Постройте две модели k-NN с различными наборами признаков. Для каждой модели проведите оценку на тестовом наборе данных при разных значениях k. Выберите несколько различных значений k. Постройте матрицу ошибок.\n",
    "\n",
    "### Модель 1: Признаки случайно отбираются."
   ],
   "id": "91f5c464fe3ee011"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выберем случайные признаки для модели и проведем оценку при k=3, k=5, k=10.",
   "id": "228b0159947352a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rng = np.random.default_rng(10)\n",
    "rand_feats_1 = list(rng.choice(X_df.columns, size=4, replace=False))\n",
    "rand_feats_2 = list(rng.choice(X_df.columns, size=5, replace=False))\n",
    "rand_feats_3 = list(rng.choice(X_df.columns, size=4, replace=False))\n",
    "rand_feats = [rand_feats_1, rand_feats_2, rand_feats_3]\n",
    "\n",
    "ks = [3, 5, 10]\n",
    "\n",
    "for i, k in enumerate(ks):\n",
    "    print(f\"\\n=== Случайные признаки: {rand_feats[i]}, k={k} ===\")\n",
    "    y_pred_fix, y_test_fix = run_knn_report(rand_feats[i], k=k, seed=42)\n",
    "    cm_fix = confusion_matrix_df(y_test_fix, y_pred_fix, labels=(0,1))\n",
    "    print(\"\\nМатрица ошибок:\")\n",
    "    print(cm_fix)\n",
    "    plot_confusion_matrix(cm_fix, title=f\"Confusion matrix (random), k={k})\")\n"
   ],
   "id": "51f4a91240f39773",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Модель 2: Фиксированный набор признаков, который выбирается заранее.",
   "id": "3c75326248855a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выберем фиксированный набор признаков для модели и проведем оценку при k=3, k=5, k=10.",
   "id": "7fe29204b3fad6cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fixed_features = ['Glucose', 'BMI', 'Age', 'BloodPressure']\n",
    "\n",
    "for k in [3, 5, 10]:\n",
    "    print(f\"\\n=== Фиксированные признаки: {fixed_features}, k={k} ===\")\n",
    "    y_pred_fix, y_test_fix = run_knn_report(fixed_features, k=k, seed=42)\n",
    "    cm_fix = confusion_matrix_df(y_test_fix, y_pred_fix, labels=(0,1))\n",
    "    print(\"\\nМатрица ошибок:\")\n",
    "    print(cm_fix)\n",
    "    plot_confusion_matrix(cm_fix, title=f\"Confusion matrix (fixed, k={k})\")\n"
   ],
   "id": "a1a64467beff8ada",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
